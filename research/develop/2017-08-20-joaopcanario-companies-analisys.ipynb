{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Companies Analisys: exploring data of companing with same name\n",
    "\n",
    "This notebook provides an exploratory analysis on companies with the same name but different CNPJ's. On this analysis it'll be tried to know more about their existence through an exploratory analysis, and possibly get more insights for new irregularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from serenata_toolbox.datasets import Datasets\n",
    "from pylab import rcParams\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Charts styling\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 15, 8\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "pd.options.display.max_rows = 100000\n",
    "pd.options.display.max_columns = 10000\n",
    "\n",
    "# First, lets download all the needed datasets for this analysis\n",
    "datasets = Datasets('../data/')\n",
    "                             \n",
    "reimbursments_path = Path(\"../data/2017-07-04-reimbursements.xz\")\n",
    "companies_path = Path(\"../data/2017-05-21-companies-no-geolocation.xz\")\n",
    "\n",
    "if not reimbursments_path.exists():\n",
    "    datasets.downloader.download('2017-07-04-reimbursements.xz')\n",
    "\n",
    "if not companies_path.exists():\n",
    "    datasets.downloader.download('2017-05-21-companies-no-geolocation.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading companies dataset\n",
    "CP_DTYPE =dict(cnpj=np.str, name=np.str,\n",
    "               main_activity_code='category', legal_entity='category',\n",
    "               partner_1_name=np.str, partner_1_qualification='category',\n",
    "               partner_2_name=np.str, partner_2_qualification='category',\n",
    "               situation='category', state='category',\n",
    "               status='category', type='category')\n",
    "\n",
    "companies = pd.read_csv(str(companies_path),\n",
    "                        dtype=CP_DTYPE, low_memory=False,\n",
    "                        parse_dates=['last_updated', 'situation_date', 'opening'])\n",
    "\n",
    "# Cleaning columns with more then 30000 NaN values\n",
    "# companies = companies.dropna(axis=[0, 1], how='all').dropna(axis=1, thresh=30000)\n",
    "companies['cnpj'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "\n",
    "c = companies[['cnpj', 'last_updated', 'legal_entity', 'main_activity_code',\n",
    "               'name', 'opening', 'partner_1_name', 'partner_1_qualification',\n",
    "               'partner_2_name', 'partner_2_qualification',\n",
    "               'situation', 'situation_date', 'state', 'status', 'type']]\n",
    "\n",
    "c.columns.values[0] = 'cnpj_cpf'\n",
    "\n",
    "c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading reimbursments dataset\n",
    "R_DTYPE =dict(cnpj_cpf=np.str, year=np.int16, month=np.int16,\n",
    "              installment='category', term_id='category',\n",
    "              term='category', document_type='category',\n",
    "              subquota_group_id='category',\n",
    "              subquota_group_description='category',\n",
    "              subquota_number='category', state='category',\n",
    "              party='category')\n",
    "\n",
    "reimbursements = pd.read_csv(str(reimbursments_path),\n",
    "                             dtype=R_DTYPE, low_memory=False, parse_dates=['issue_date'])\n",
    "\n",
    "r = reimbursements[['year', 'month', 'total_net_value', 'party',\n",
    "                    'state', 'term', 'issue_date', 'congressperson_name',\n",
    "                    'subquota_description','supplier', 'cnpj_cpf']]\n",
    "\n",
    "r.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.groupby(['supplier', 'congressperson_name', 'year'])['total_net_value'].sum().sort_values(ascending=False).head(20)\n",
    "filtered_c = c[c['cnpj_cpf'].isin(r.cnpj_cpf.unique())]\n",
    "data = r.merge(filtered_c, on='cnpj_cpf', how='left')\n",
    "data = data[data.year >= 2016]\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count objects with invalid main_activity_code\n",
    "d = dict()\n",
    "\n",
    "invalid_main_activity = \"00.00-0-00\"\n",
    "data_len = len(data)\n",
    "\n",
    "d['valid'] = len(data[data.main_activity_code != invalid_main_activity]) / data_len * 100\n",
    "d['invalid'] = len(data[data.main_activity_code == invalid_main_activity]) / data_len * 100\n",
    "\n",
    "s = pd.Series(d)\n",
    "s.plot(kind='pie', autopct='%.2f')\n",
    "plt.title('Number of valid and invalid main_activity_code in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items with invalid main_activity_code\n",
    "data = data[data.main_activity_code != \"00.00-0-00\"]\n",
    "print('dataset shape: {}.'.format(data.shape))\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['party', 'state_x', 'term', 'issue_date', 'congressperson_name', \n",
    "          'subquota_description', 'supplier', 'cnpj_cpf', 'legal_entity', \n",
    "          'main_activity_code', 'name', 'partner_1_name', 'partner_1_qualification', \n",
    "          'partner_2_name', 'partner_2_qualification', 'situation', 'state_y',\n",
    "          'status', 'type']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for l in labels:\n",
    "    df[l] = data[l].astype('category').cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df = scale(df)\n",
    "\n",
    "# Benchmark clusters\n",
    "X, _, = train_test_split(df, train_size=0.2, random_state=2)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(42 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\tsilhouette')\n",
    "\n",
    "def bench_k_means(estimator, name, data, labels=0):\n",
    "    t0 = time()\n",
    "    print('antes do fit')\n",
    "    estimator.fit(data)\n",
    "    print('depois do fit')\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.silhouette_score(data, estimator.labels_, metric='euclidean')))\n",
    "\n",
    "bench_k_means(KMeans(n_clusters=2,  n_init=10), name=\"KMeans (20)\", data=X)\n",
    "# bench_k_means(KMeans(n_clusters=3), name=\"KMeans (30)\", data=X)\n",
    "# bench_k_means(KMeans(n_clusters=4), name=\"KMeans (40)\", data=X)\n",
    "# bench_k_means(KMeans(n_clusters=5), name=\"KMeans (50)\", data=X)\n",
    "\n",
    "bench_k_means(KMeans(n_clusters=2), name=\"PCA-based (20)\", data=PCA(n_components=2).fit(X).compents_)\n",
    "# bench_k_means(KMeans(init=PCA(n_components=30).fit(X).components_, n_clusters=30,  n_init=1),\n",
    "#               name=\"PCA-based (30)\", data=X)\n",
    "# bench_k_means(KMeans(init=PCA(n_components=40).fit(X).components_, n_clusters=40,  n_init=1),\n",
    "#               name=\"PCA-based (40)\", data=X)\n",
    "# bench_k_means(KMeans(init=PCA(n_components=50).fit(X).components_, n_clusters=50,  n_init=1),\n",
    "#               name=\"PCA-based (50)\", data=X)\n",
    "\n",
    "print(42 * '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
